---
title: "732A75-Clustering Lab"
author: "Rabnawaz(rabsh696) & Saman Zahid(samza595)"
date: "2/18/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# SimpleKMeans

__Note: using the feature of ignore attribute in weka before running KMeans__

## 1. Choose a set of attributes for clustering and give a motivation.

__Name__ attribute must be ignored because `name` is a categorical variable while k-means algorithm work on continuous numerical values. All other attributes(Energy, Protein, Fat, Calcium, Iron) are continuous thus all other attributes can be selected for clustering.

## 2. Experiment with at least two different numbers of clusters

### Basic Information for the procedure

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/1.png)


### KMeans Method with 2 Clusters with seed value 10(rest of the setting remains default

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/2.png)

### KMeans Method with 5 Clusters with seed value 10(rest of the setting remains default)

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/3.png)




## 3. Compare result with previous results. i.e. with different initial cluster centers.

In part 3, by changing seed, the initial randomly chosen centroid value changes, due to which the entire clustering is changed. By changing the seed value from 10 to 5, the same clusters are formed but in different order in both cases (number of clusters = 2 or 5) with the same number of iterations and error rate. But by increasing the seed (for seed =15) the number of objects in each cluster, the formation of cluster (that is cluster centroid) instances changes a lot.

### KMeans Method with 2 Clusters with seed value 5(rest of the setting remains default)

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/4.png)


### KMeans Method with 5 Clusters with seed value 5(rest of the setting remains default)

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/5.png)

### KMeans Method with 2 Clusters with seed value 15(rest of the setting remains default)

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/6.png)


### KMeans Method with 5 Clusters with seed value 15(rest of the setting remains default)

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/7.png)

## 4. Do you think the clusters are good clusters? (Are all of its members "similar" to each other? Are members from different clusters dissimilar?)

In my opinion the clusters formed are not good, it is because the objects are dispersed and by taking a random initial centroid, it might be possible that centroid is near the outlier which can result in misclassifying the dissimilar to be similar and put together in same cluster. 

As from visualization, it can also be observed that the position of objects with very high and very low value differs. Due to very high variance, the possibility of #having outliers increases. and k-mean does not work well with outliers.

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/8.png)


## 5. What does each cluster represent? Choose one of the results. Make up labels which characterize each cluster.

I choose the result with 2 clusters and seed = 10. It can be observed that for cluster 0, energy is very high, fat is high while calcium is low, while for cluster 1, energy is comparatively low, fat is low, and calcium is high. Protein and iron value for both clusters are almost same. So, on the basis of this observation i would name cluster 0 as "High fat low calcium" and cluster 1 as "low fat high calcium" cluster.


![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/9.png)

\newpage
# MakeDensityBasedClusters


## 1. Use the SimpleKMeans clusterer which gave the result you have chosen in 5.

we run the density-based clustering algorithm with number of cluster that we have selected in question 1 part 5 which is 2 and seed value 10 with default standard deviation that is the minimum standard deviation $1~~X~~10^{-6}$

## 2.	Experiment with at least two different standard deviations. Compare the results..

Part 2: By taking standard deviation first as min standard deviation $1~~X~~10^{-6}$, the cluster formed has a difference of 1 object as compared to what we got from k-means algorithm. 

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/10.png)

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/11.png)

By keeping standard deviation = 1, the result exactly the same as we got from k-means algorithm in question 1 part 5.

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/12.png)

Then keeping the standard deviation equals to 100 gives very different result, classifying more objects in "low fat high calcium" cluster". But it can also be observed that increasing the standard deviation further beyond this point gives the same cluster and the standard deviation of all attributes almost become same.

![](/Users/rabnawaz/Documents/study martial/Semester 2/advanced data mining/labs/lab1-report/13.png)


We know that density-based clustering searches for the density reachable point (objects) from the randomly chosen point. By increasing the standard deviation, the variance increases, due to which the object which was initially density reachable from first cluster "High fat low calcium" cluster then became density reachable from "low fat high calcium" cluster. Notice that only the standard deviation of attributes changes in result and mean remains same throughout the process.